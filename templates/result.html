<!DOCTYPE html>
<html>
  <head>
    <title></title>
    <link
      rel="stylesheet"
      type="text/css"
      href="{{ url_for('static', filename='css/styles.css') }}"
    />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous"
    />
  </head>
  <body>
    <header>
      <div class="container">
       <h1 class="text-center">Spam Detector For SMS Messages</h1>
      <img class="img-fluid" id="banner" src="static/image/sms.png" />
      <h2 class="text-center">About MultinomialNB Algorithm used for building Span Detector</h2>
      </div>
    </header>

    <div class="container">
		<p class="lead">
         Naive Bayes classifier for multinomial models. The multinomial Naive
        Bayes classifier is suitable for classification with discrete features
        (e.g., word counts for text classification). The multinomial
        distribution normally requires integer feature counts. However, in
        practice, fractional counts such as tf-idf may also work. Naive Bayes is
        a probabilistic classification algorithm that applies Bayes' theorem
        with an assumption of independence between features. It calculates the
        probabilities of a data point belonging to each class and assigns it to
        the class with the highest probability. MultinomialNB extends the Naive
        Bayes algorithm to handle multiclass classification problems, where
        there are more than two classes. It assumes that the features'
        probability follows a multinomial distribution, which makes it suitable
        for text classification tasks where features represent counts or
        frequencies of word occurrences in documents. In text classification,
        MultinomialNB can be trained on a labeled dataset of documents, where
        each document is represented by the word counts or term
        frequency-inverse document frequency (TF-IDF) values. It then uses these
        features to calculate the probabilities of a new document belonging to
        each class. The class with the highest probability is assigned as the
        predicted class for the document. 
		</p>
		
		<p class="lead">
		We also use CountVectorizer as a text
        preprocessing technique for converting a collection of text documents
        into a numerical matrix representation. It is a feature extraction
        method used to transform text data into a format suitable for machine
        learning algorithms. Once the model is build, we can use it to predict
        whether a message is spam or not. We have used Flask to display the
        prediction on web browser. We have also used HTML and CSS to design the
		web page.
		</p>

      <p class="lead">
        <h3>Prediction for given SMS</h3>
      </p>
      <div class="results">
        <p class="lead">
          <b>{{ message }}</b>
        </p>

        <h3>Results:</h3>
		{% if prediction == 1%}
        <h4 style="color: red">Spam</h4>
		<span style='font-size:100px;'>&#128545;</span>
        {% elif prediction == 0%}
        <h4 style="color: blue">Not a Spam (It is a Ham)</h4>
		<span style='font-size:100px;'>&#128512;</span>
        {% endif %}
      </div>
    </div>
  </body>
</html>
